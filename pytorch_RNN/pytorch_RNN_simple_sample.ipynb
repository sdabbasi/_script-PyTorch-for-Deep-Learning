{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731a9dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88815ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(0, 799, 800)\n",
    "y = torch.sin(x*2*3.1416/40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bea229",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.xlim(-10, 810)\n",
    "plt.grid(True)\n",
    "plt.plot(y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970bff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we split the data to train and test section\n",
    "test_size = 40\n",
    "train_set = y[:-test_size]\n",
    "test_set = y[-test_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58255b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.xlim(-10, 810)\n",
    "plt.grid(True)\n",
    "plt.plot(train_set.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7f7680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we divide the training data to sequences that can be feeded to the network\n",
    "def input_data(data_seq, window_size):\n",
    "    out = []      # 'out' would be like this : [([0,1,2,3],[4]), ([1,2,3,4],[5]), ([2,3,4,5],[6]), ...]\n",
    "    \n",
    "    for i in range(len(data_seq)-window_size):\n",
    "        window = data_seq[i:i+window_size]\n",
    "        label = data_seq[i+window_size:i+window_size+1]\n",
    "        out.append((window, label))\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64b43ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 40\n",
    "train_data = input_data(train_set, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47c9e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21aab86",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720f881d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e538bc65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ac978b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelLSTM(nn.Module):\n",
    "    # \"input_size\" is 1 because we have one 'y' value per timestamp\n",
    "    # \"hidden_size\" is the number lstm neurons inside the LSTM layer which is located before the fully connected layer\n",
    "    # \"out_size\" is 1 becuase we produce one value as label\n",
    "    def __init__(self, input_size=1, hidden_size=50, out_size=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size)\n",
    "        \n",
    "        self.linear = nn.Linear(hidden_size, out_size)\n",
    "        \n",
    "        # placeholder for hidden-state and cell-state\n",
    "        self.hidden_state_cell_state = (torch.zeros(1,1,hidden_size), torch.zeros(1,1,hidden_size))\n",
    "        \n",
    "    def forward(self, data_seq):\n",
    "        lstm_out, self.hidden_state_cell_state = self.lstm(data_seq.view(len(data_seq),1,-1),self.hidden_state_cell_state)\n",
    "        pred = self.linear(lstm_out.view(len(data_seq), -1)[-1])\n",
    "        \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c378dbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model = ModelLSTM()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d106c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    print(param.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e32291",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "future_points = 40\n",
    "\n",
    "for i in range(epochs):\n",
    "    for data_seq, y_train in train_data:\n",
    "        # first have to reset the parameters and hidden states\n",
    "        optimizer.zero_grad()\n",
    "        model.hidden_state_cell_state = (torch.zeros(1,1,model.hidden_size),torch.zeros(1,1,model.hidden_size))\n",
    "        \n",
    "        y_pred = model.forward(data_seq)\n",
    "        \n",
    "        loss = criterion(y_pred, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f\"Epoch:{i} loss:{loss.item()}\")\n",
    "    \n",
    "    preds = train_set[-window_size:].tolist()\n",
    "    for f in range(future_points):\n",
    "        seq = torch.FloatTensor(preds[-window_size:])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.hidden_state_cell_state = (torch.zeros(1,1,model.hidden_size),torch.zeros(1,1,model.hidden_size))\n",
    "            preds.append(model.forward(seq).item())\n",
    "    loss = criterion(torch.tensor(preds[-window_size:]), y[760:])\n",
    "    print(f\"Performance on the test range; the loss: {loss}\")\n",
    "    \n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.xlim(700,801)\n",
    "    plt.grid(True)\n",
    "    plt.plot(y.numpy())\n",
    "    plt.plot(range(760,800), preds[window_size:])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d274d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f738d378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we want to use all the possible data for training and use the last section to 'forcast into unknown future':\n",
    "epochs = 15\n",
    "window_size = 40\n",
    "future = 40\n",
    "\n",
    "all_data = input_data(y, window_size)\n",
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6673f957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(epochs):\n",
    "    for data_seq, y_train in all_data:\n",
    "        # first have to reset the parameters and hidden states\n",
    "        optimizer.zero_grad()\n",
    "        model.hidden_state_cell_state = (torch.zeros(1,1,model.hidden_size),torch.zeros(1,1,model.hidden_size))\n",
    "        \n",
    "        y_pred = model.forward(data_seq)\n",
    "        \n",
    "        loss = criterion(y_pred, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f\"Epoch:{i} loss:{loss.item()}\")\n",
    "\n",
    "total_time = time.time()-start_time\n",
    "print(f'The training time is: {total_time/60} mins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d760e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now use the trained model for forcasting:\n",
    "preds = y[-window_size:].tolist()\n",
    "for f in range(future):\n",
    "    seq = torch.FloatTensor(preds[-window_size:])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.hidden_state_cell_state = (torch.zeros(1,1,model.hidden_size),torch.zeros(1,1,model.hidden_size))\n",
    "        preds.append(model.forward(seq).item())\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.xlim(0,841)\n",
    "plt.grid(True)\n",
    "plt.plot(y.numpy())\n",
    "plt.plot(range(800,800+future), preds[window_size:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5c5f58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('myMLEnv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "418a5ed4ed6d8198b840b61453495c26d507d70d3841dd181a7388aaa4474a5c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
